{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "The raw code for this Jupyter notebook is by default hidden for easier reading.\n",
       "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.\n",
       "<style>\n",
       ".output_png {\n",
       "    display: table-cell;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for this Jupyter notebook is by default hidden for easier reading.\n",
    "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](data/TITLE.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Module 01: Introduction </center></h1>\n",
    "\n",
    "In my experience, (geophysical) digital signal processing (or \"DigSig\") represents one of the most important sequences of steps that we geophysicists use when taking geophysical data recorded in the field and generating our desired geophysical analysis outputs (i.e., models, images) that are used in publications, reports and theses. \n",
    "\n",
    "However, there are many challenges that early-career geophysicists face when starting out on this path.  In particular, with geophysical data (like in other disciplines) there are many many many different **processing strategies** and **algorithms** to choose from, the **order of processing workflow** must be developed, and this usually involved selecting values for scores of different **parameters**.  Is there a right or wrong way to process the data? How does one establish a judicious, well thought out, and computationally efficient workflow? In many ways it might seem to someone coming in (and indeed the same is felt by many other geoscientists that use our end products!) that the following must be true:\n",
    "\n",
    "$$ \n",
    "\\boxed{\\begin{array}{c}\\mathrm{Field}\\\\\\mathrm{Geophysical}\\\\\\mathrm{Data}\\end{array}}\n",
    "\\Longrightarrow \n",
    "\\boxed{\\begin{array}{c}\\mathrm{Magic\\,Black}\\\\\\mathrm{Box\\,of\\, Geophysical}\\\\\\mathrm{Data\\,Processing}\\end{array}}\n",
    "\\Longrightarrow \n",
    "\\boxed{\\begin{array}{c}\\mathrm{Top-notch}\\\\\\mathrm{Geophysical}\\\\\\mathrm{Result}\\end{array}}\n",
    "$$\n",
    "\n",
    "**Figure 1. What digital signal processing might seem to some at this point.  Just say NO! to Black Box**\n",
    "\n",
    "One of the major goals of this class is to strip away some of the **magic black box** nature of geophysical data procesing, and give you a better conceptual idea of how to analyze your geophysical data. Ideally, this will help you to design better data processing workflows that allow us to achieve our geophsical data processing goals (e.g., noise removal, signal enhancement, interpretable geophysical result).\n",
    "\n",
    "In the sections below I present two examples that (hopefully!) show the value of applying  digital signal processing to geophysical field data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASC93 Seismic Experiment\n",
    "\n",
    "The goal of the CASC93 experiment was to obtain recording of distant (so-called teleseismic) earthquakes that would provide us with some idea about the lithospheric structure in a seismically quiessent zone located in west-central Oregon.  The acquisition of this data set on a linear array of 40 three component stations created a fantastic opportunity to apply the concepts 2D migration to study the top 120 km of lithosphere!\n",
    "\n",
    "\n",
    "(a) CASC93 Experiment Location | (b) Earthquake Locations\n",
    "- | - \n",
    "<img src=\"Fig/EQMIG1.png\" width=\"450\"> | <img src=\"Fig/EQMIG1B.png\" width=\"400\">\n",
    "\n",
    "**Figure 2. (a) Location of the CASC93 seismic experiment involving 40 three-component broadband seismic stations deployed over 300 km in Oregon. (b) Locations of the large earthquakes (i.e., > 5.5 Mb) used for imaging that originated $30^\\circ <\\Delta<90^\\circ$ from array.**\n",
    "\n",
    "<img src=\"Fig/EQMIG2.png\" width=\"400\">\n",
    "\n",
    "**Figure 3. Example of a processed earthquake arrival recorded on a multicomponent seismic array. Recorded earthquake signals were subject to much digital signal processing: automated windowing (based on short-time versus long-time signal magnitudes esimates), bandpass filtering (within the source signal band), polarity filtering (to account for directivity of source), estimation and deconvolution of source signatures (to estimate the impulse response), and regularization into a regular grid for plotting (for ease of applying migration operators)**.\n",
    "\n",
    "<img src=\"Fig/EQMIG4.png\" width=\"500\">\n",
    "\n",
    "**Figure 4. Stack of all recorded earthquakes after imaging+inversion. The interpretation of the structure shown in this figure is the Juan de Fuca Plate subducting beneath the North American continental plate. Note that this final step involved applying full-wavefield migration, which is also a digital filter.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microseismic Velocity Inversion\n",
    "\n",
    "You have no doubt heard about the link between subsurface fluid injection activities (i.e., fracing) and induced (micro)seismicity into prolific shale formations of very low permeability.  In most cases, the magnitudes of induced microseismic events are quite low (< 1.0 Mw), and it is helpful for the operators to know where and when these events occur because they provide important details as to how the stimulation increases fault connectivity and overall permeability.  \n",
    "\n",
    "There are now a number of specialized microseismic operators that deploy tens-to-hundreds of multi-component seismic stations (see Figure 4) that are sufficiently sensitive to record **very weak microseismic events** (e.g., $-1.25<Mw<0.25$) occurring at 1.0-2.0 km depth. \n",
    "\n",
    "<img src=\"Fig/MICRO00.png\" width=\"500\">\n",
    "\n",
    "**Figure 5. Example field deployment of 192 3C sensors over the Marcellus Shale formation in Ohio. The overall area of investigation is 6$\\times$6 km$^2$, while the white box shows the 1.5$\\times$1.25 km$^2$ area of subsurface stimulated at approximately 2.0 km depth.** \n",
    "\n",
    "Two windowed raw microseismic events | Events processed into P- and S-wave through DSP\n",
    "- | - \n",
    "<img src=\"Fig/MICRO1.png\" width=\"500\"> | <img src=\"Fig/MICRO2.png\" width=\"350\">\n",
    "\n",
    "**Figure 6. (a) Example of a weak (upper panels) and a very weak (lower panels) microseismic event, where the three subpanels represent the vertical, easting and northing components. (b) The same two events after significant digital signal processing: data windowing (again based on long-term versus short-term signal averages), wave-mode separation (to isolate P- and S-wave contributions), band-pass filtering (to within expected range), envelope estimation (to handle S-wave polarities), and second pass of bandpass filtering (to return signals to zero mean).**\n",
    "\n",
    "Usually, these data sets are acquired in frontier exploration areas that do have no 3D (or even 2D) seismic data, which are essential for generating information as the local 3D velocity structure.  (In fact, commonly the only velocity constraint in the area is a single borehole located a few kilometers away that might only be logged in the interval of interest!)  Thus, the question is: **how can you locate source of a very noisy microseismic event if you do not know the 3D velocity structure and you do not know at what time and where it occured?**  \n",
    "\n",
    "When at the University of Western Australia (UWA), my PhD student Ben Witten and I developed a method to take the processed microseismic signals and go through a process of **adjoint-state inversion** to jointly estimate the 3D velocity structure and optimize microseismic event locations.  Figure 6 shows the results before (left two panels) and after (right two panels) applying the velocity inversion method.  The upper and lower panels show the P- and S-wave velocity structure, respectively.  Overall, through the inversion process there is a significant improvement in the consistency of event locations - and potentially imaging of a stimulated fault.\n",
    "\n",
    "Before Inversion | After Inversion\n",
    "- | - \n",
    "<img src=\"Fig/MICRO3.png\" width=\"400\"> | <img src=\"Fig/MICRO4.png\" width=\"400\">\n",
    "\n",
    "**Figure 7. The inital (a) P-wave and (b) S-wave velocity structure used to generate initial location estimates (white stars).  The (c) P-wave and (d) S-wave velocity structure used to generate the final location estimates. Much more consistent locations are now observed, and (almost) all events fall within the expected interval. The quality of the final result is heavily dependent on the digital signal processing choices made during the preprocessing stages.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Outline\n",
    "\n",
    "This introductory course on geophysical digital signal processing covers a lot of fundamental mathematical and numerical topics that you will need in your career as a geophysicist or more broadly when playing a quantitative role in the physical sciences.\n",
    "\n",
    "### Module 01 - Introduction \n",
    "\n",
    "The purpose of this module is to emphasize how fundamental DSP has been to your instructor in his career, and to highlight the key topics that will be investigated in this course.\n",
    "\n",
    "### Module 02 - Terminology of Digital Signal Processing\n",
    "\n",
    "This short module introduces some key tems used DSP.\n",
    "\n",
    "### Module 03 - Complex Numbers\n",
    "\n",
    "This module provides a refresher on the manipulation of complex numbers and functions, which are fundamental building blocks for the material developed later on in the course.\n",
    "\n",
    "### Module 04 - Fourier Series\n",
    "\n",
    "This module starts to build up the Fourier machinary by examining time series that are periodic.  We start looking at and calculating Fourier spectra that are a very helpful tool for examining signals in a different light.\n",
    "\n",
    "### Module 05 - 1D Fourier Transforms\n",
    "\n",
    "In this module we examine both the analytical and numerical properties of the 1D Fourier transform. We also look at Fourier transform of a number of important analytic signals as well as that of instrument, earthquakes and seismic data.\n",
    "\n",
    "### Module 06 - 2D Fourier Transforms\n",
    "\n",
    "This module extends the 1D Fourie analysis presented in Module 5 to 2D images. Concepts of 2D spatial filtering are introduced.\n",
    "\n",
    "### Module 07 - Linear Time Invariant (LTI) systems\n",
    "\n",
    "This module introduces the concepts of linear time-invariant (LTI) systems, including the operations of convolution, correlation, autocorrelation and deconvolution.\n",
    "\n",
    "### Module 08 - Discrete Time Signals\n",
    "\n",
    "This module introduces a number of important concepts regarding discrete time series including: continuous vs discrete vs digital signals; deterministic vs stochastic signals; and characteristics of LTI systems.\n",
    "\n",
    "### Module 09 - Digital Sampling and Reconstruction\n",
    "\n",
    "This module explores the key consequences of performing digital sampling (i.e., aliasing), discusses strategies to avoid aliasing, and how to reconstruct analog signals from properly sampled time series.\n",
    "\n",
    "### Module 10 - Discrete Fourier Transform\n",
    "\n",
    "This module looks at how we can take 1D/2D Fourier transforms that we defined in a continuous fashion in the modules above and looks at how they can be posed in discrete systems.\n",
    "\n",
    "### Module 11 - Windows and Spectrograms\n",
    "\n",
    "This module looks at how we can go beyond Fourier transforms that span the entire time series to those that provide more information on the \"local\" frequency information.\n",
    "\n",
    "### Module 12 - Z Transforms\n",
    "\n",
    "This module looks at how we can generalize Discrete Fourier Transforms to more generalized and abstract spaces.\n",
    "\n",
    "### Module 13 - Practical Filtering\n",
    "\n",
    "We finish the course by looking how Z-Transforms can be use to set up FIR and IIR filters that can be used to do a whole bunch of useful things such as lowpass, highpass, bandpass and band reject filtering of 1D signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
